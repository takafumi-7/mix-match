{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"rARySeM1GXDB","colab_type":"code","outputId":"618c434e-4d77-49ba-ac3d-b55c75a4bb05","executionInfo":{"status":"error","timestamp":1558875610417,"user_tz":-540,"elapsed":2873,"user":{"displayName":"藤井隆史","photoUrl":"","userId":"02292301144144879183"}},"colab":{"base_uri":"https://localhost:8080/","height":409}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","batch_size = 500\n","augmentation_time = 3\n","alpha = 0.5\n","\n","sess = tf.InteractiveSession()\n","\n","#入力値のplaceholderを作成（ラベル付きデータとラベル無しデータを分けて作成）\n","labeled_x = tf.placeholder(tf.float32, shape=(None, 28, 28, None))\n","unlabeled_x = tf.placeholder(tf.float32, shape=(None, 28, 28, None))\n","y = tf.placeholder(tf.float32, shape=(None,10))\n","\n","\n","#ラベル付きデータを-90°, -45°, 45°, 90°の間でランダムに回転（Augmentation）した画像を追加\n","extended_labeled_x = tf.concat([labeled_x, tf.contrib.image.rotate(labeled_x, np.random.choice([-90, -45, 45, 90]))], axis=0)\n","\n","#ラベル無しデータを-90°, -45°, 45°, 90°の間でランダムに回転（Augmentation）した画像をaugmentation_timeセット追加\n","extended_unlabeled_x_set = [unlabeled_x]\n","for i in np.random.choice([-90, -45, 45, 90], augmentation_time):\n","  extended_unlabeled_x_set.append(tf.contrib.image.rotate(unlabeled_x, i))\n","\n","#ラベル無しデータの各セットの予測値の平均を算出\n","average_prediction_unlabeled = tf.zeros([batch_size, 10], dtype=tf.float32)\n","extended_unlabeled_x = tf.zeros([0, 28, 28, 1], dtype=tf.float32)\n","counter = 0\n","for unlabeled_dataset in extended_unlabeled_x_set:\n","  input_layer = tf.reshape(unlabeled_dataset, [-1, 28, 28, 1])\n","  conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[4, 4], padding=\"same\", activation=tf.nn.relu)\n","  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n","  dropout1 = tf.layers.dropout(inputs=pool1, rate=0.2)\n","  conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n","  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n","  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n","  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n","  dropout = tf.layers.dropout(inputs=dense, rate=0.2)\n","  logits = tf.layers.dense(inputs=dropout, units=10)\n","  average_prediction_unlabeled = average_prediction_unlabeled + logits\n","  extended_unlabeled_x = tf.concat([extended_unlabeled_x, unlabeled_dataset], axis=0)\n","  counter += 1\n","average_prediction_unlabeled = average_prediction_unlabeled / counter\n","extended_prediction_unlabeled = tf.zeros([0, 10], dtype=tf.float32)\n","for i in range(augmentation_time+1):\n","  extended_prediction_unlabeled = tf.concat([extended_prediction_unlabeled, average_prediction_unlabeled], axis=0)\n","\n","#ラベル無しデータの各セットの平均予測値をsharpeningする\n","\n","\n","#ラベル付きデータとラベル無しデータを行方向に連結し、シャッフルした行列Wを作成する\n","not_shuffled_W_x = tf.concat([extended_labeled_x, extended_unlabeled_x], axis=0)\n","not_shuffled_W_y = tf.concat([y, extended_prediction_unlabeled], axis=0)\n","shuffled_index = np.random.permutation(range(batch_size*(augmentation_time+1)))\n","indexes = tf.where(shuffled_index)\n","W_x, W_y = tf.gather_nd(not_shuffled_W_x, indexes), tf.gather_nd(not_shuffled_W_y, indexes)\n","\n","#Mixupを実施\n","lam = np.random.beta(alpha, alpha)\n","mixed_labeled_x = lam*extended_labeled_x + (1-lam)*W_x[:batch_size*2]\n","mixed_labeled_y = lam*y + (1-lam)*W_y[:batch_size*2]\n","mixed_unlabeled_x = lam*extended_unlabeled_x + (1-lam)*W_x[batch_size*2:]\n","mixed_unlabeled_y = lam*extended_prediction_unlabeled + (1-lam)*W_y[:batch_size*2]\n","\n","# ラベル付きデータの損失関数\n","input_layer = tf.reshape(mixed_labeled_x, [-1, 28, 28, 1])\n","conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[4, 4], padding=\"same\", activation=tf.nn.relu)\n","pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n","dropout1 = tf.layers.dropout(inputs=pool1, rate=0.2)\n","conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n","pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n","pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n","dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n","dropout = tf.layers.dropout(inputs=dense, rate=0.2)\n","logits = tf.layers.dense(inputs=dropout, units=10)\n","labeled_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = mixed_labeled_y) / tf.matrix_determinant(mixed_labeled_x)\n","\n","# ラベル無しデータの損失関数\n","input_layer = tf.reshape(mixed_unlabeled_x, [-1, 28, 28, 1])\n","conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[4, 4], padding=\"same\", activation=tf.nn.relu)\n","pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n","dropout1 = tf.layers.dropout(inputs=pool1, rate=0.2)\n","conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n","pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n","pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n","dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n","dropout = tf.layers.dropout(inputs=dense, rate=0.2)\n","logits = tf.layers.dense(inputs=dropout, units=10)\n","unlabeled_loss = tf.reduce_sum(tf.square(mixed_unlabeled_y - logits)) / (tf.matrix_determinant(mixed_unlabeled_x)*y.shape[1])\n","\n","\n","# 最適化\n","\n","#予測値・accuracyの算出"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-75d79537dd54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mlabeled_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixed_labeled_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_determinant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_labeled_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# ラベル無しデータの損失関数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   2645\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[1;32m   2646\u001b[0m                        \u001b[0;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[1;32m   2648\u001b[0m     if (static_shapes_fully_defined and\n\u001b[1;32m   2649\u001b[0m         labels_static_shape != logits.get_shape()[:-1]):\n","\u001b[0;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2)."]}]},{"cell_type":"code","metadata":{"id":"mBGOZ4_7CC3u","colab_type":"code","colab":{}},"source":["mnistのデータをロード\n","from keras.datasets import mnist \n","from keras.utils import np_utils\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train.reshape([-1, 28, 28, 1]).astype(np.float32), x_test.reshape([-1, 28, 28, 1]).astype(np.float32)\n","y_train, y_test = np_utils.to_categorical(y_train, 10).astype(np.float32)[:30000], np_utils.to_categorical(y_test, 10).astype(np.float32)\n","labeled_x_train, unlabeled_x_train = x_train[:30000, :, :, :], x_train[30000:, :, :, :]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KkKX3lg6E5wt","colab_type":"code","colab":{}},"source":["batch_size = 500\n","init = tf.global_variables_initializer()\n","\n","with tf.Session() as sess:\n","  init.run()\n","  for num in range(len(labeled_x_train) // batch_size):\n","    labeled_x_batch, unlabeled_x_batch, y_batch = labeled_x_train[num*batch_size:(num+1)*batch_size], unlabeled_x_train[num*batch_size:(num+1)*batch_size], y_train[num*batch_size:(num+1)*batch_size]\n","    train_accuracy = accuracy.eval(feed_dict={labeled_x: labeled_x_batch, unlabeled_x: unlabeled_x_batch, y: y_batch})\n","    sess.run(train_op, feed_dict={labeled_x: labeled_x_batch, unlabeled_x: unlabeled_x_batch, y: y_batch})\n","  print('accuracy: {}'.format(train_accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ImhOItP7nvlz","colab_type":"text"},"source":["### ラベル付きの訓練データ（30000件）のみで訓練するモデル"]},{"cell_type":"code","metadata":{"id":"2AiUukIudluj","colab_type":"code","colab":{}},"source":["#入力値のplaceholderを作成\n","labeled_x = tf.placeholder(tf.float32, shape=(None, 28, 28, None))\n","y = tf.placeholder(tf.float32, shape=(None,10))\n","\n","input_layer = tf.reshape(labeled_x, [-1, 28, 28, 1])\n","conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[4, 4], padding=\"same\", activation=tf.nn.relu)\n","pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n","dropout1 = tf.layers.dropout(inputs=pool1, rate=0.2)\n","conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n","pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n","pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n","dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n","dropout = tf.layers.dropout(inputs=dense, rate=0.2)\n","logits = tf.layers.dense(inputs=dropout, units=10)\n","\n","\n","# 損失関数\n","loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits)\n","\n","# 最適化\n","optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n","train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n","\n","prediction_match = tf.equal(tf.argmax(logits, axis=1), tf.argmax(y, axis=1))\n","accuracy = tf.reduce_mean(tf.cast(prediction_match, tf.float32), name='accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BiNWdq1WgL-b","colab_type":"code","outputId":"7b69e983-e983-4339-bfc6-85a559b460cf","executionInfo":{"status":"ok","timestamp":1558857040290,"user_tz":-540,"elapsed":63330,"user":{"displayName":"藤井隆史","photoUrl":"","userId":"02292301144144879183"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["batch_size = 500\n","init = tf.global_variables_initializer()\n","\n","with tf.Session() as sess:\n","  init.run()\n","  for num in range(len(labeled_x_train) // batch_size):\n","    labeled_x_batch, unlabeled_x_batch, y_batch = labeled_x_train[num*batch_size:(num+1)*batch_size], unlabeled_x_train[num*batch_size:(num+1)*batch_size], y_train[num*batch_size:(num+1)*batch_size]\n","    train_accuracy = accuracy.eval(feed_dict={labeled_x: labeled_x_batch, unlabeled_x: unlabeled_x_batch, y: y_batch})\n","    sess.run(train_op, feed_dict={labeled_x: labeled_x_batch, unlabeled_x: unlabeled_x_batch, y: y_batch})\n","  print('accuracy: {}'.format(train_accuracy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["accuracy: 0.9399999976158142\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vd7O-aegzyqD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}