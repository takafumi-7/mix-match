{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mix_match.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qg0S2Eow9iT9","colab_type":"text"},"source":["### MixMatchによる半教師あり学習で訓練するモデル（ラベル付きデータ30000件、ラベル無しデータ30000件）"]},{"cell_type":"code","metadata":{"id":"rARySeM1GXDB","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","batch_size = 500\n","augmentation_time = 3\n","alpha = 0.5\n","T = 0.5\n","\n","sess = tf.InteractiveSession()\n","\n","#入力値のplaceholderを作成（ラベル付きデータとラベル無しデータを分けて作成）\n","labeled_x = tf.placeholder(tf.float32, shape=(None, 28, 28, None))\n","unlabeled_x = tf.placeholder(tf.float32, shape=(None, 28, 28, None))\n","y = tf.placeholder(tf.float32, shape=(None,10))\n","\n","\n","#ラベル付きデータを-90°, -45°, 45°, 90°の間でランダムに回転（Augmentation）した画像を追加\n","extended_labeled_x = tf.concat([labeled_x, tf.contrib.image.rotate(labeled_x, np.random.choice([-90, -45, 45, 90]))], axis=0)\n","\n","#ラベル無しデータを-90°, -45°, 45°, 90°の間でランダムに回転（Augmentation）した画像をaugmentation_timeセット追加\n","extended_unlabeled_x_set = [unlabeled_x]\n","for i in np.random.choice([-90, -45, 45, 90], augmentation_time):\n","  extended_unlabeled_x_set.append(tf.contrib.image.rotate(unlabeled_x, i))\n","\n","#ラベル無しデータの各セットの予測値の平均を算出\n","average_prediction_unlabeled = tf.zeros([batch_size, 10], dtype=tf.float32)\n","extended_unlabeled_x = tf.zeros([0, 28, 28, 1], dtype=tf.float32)\n","counter = 0\n","for unlabeled_dataset in extended_unlabeled_x_set:\n","  input_layer = tf.reshape(unlabeled_dataset, [-1, 28, 28, 1])\n","  conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[4, 4], padding=\"same\", activation=tf.nn.relu)\n","  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n","  dropout1 = tf.layers.dropout(inputs=pool1, rate=0.2)\n","  conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n","  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n","  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n","  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n","  dropout = tf.layers.dropout(inputs=dense, rate=0.2)\n","  logits = tf.layers.dense(inputs=dropout, units=10)\n","  average_prediction_unlabeled = average_prediction_unlabeled + logits\n","  extended_unlabeled_x = tf.concat([extended_unlabeled_x, unlabeled_dataset], axis=0)\n","  counter += 1\n","average_prediction_unlabeled = average_prediction_unlabeled / counter\n","\n","#ラベル無しデータの各セットの平均予測値をsharpeningする\n","sharpened_prediction = tf.pow(average_prediction_unlabeled, 1/T) / tf.transpose(tf.add(tf.zeros([10, batch_size]), tf.reduce_sum(tf.pow(average_prediction_unlabeled, 1/T), 1)))\n","extended_prediction_unlabeled = tf.zeros([0, 10], dtype=tf.float32)\n","for i in range(augmentation_time+1):\n","  extended_prediction_unlabeled = tf.concat([extended_prediction_unlabeled, sharpened_prediction], axis=0)\n","\n","#ラベル付きデータとラベル無しデータを行方向に連結し、シャッフルした行列Wを作成する\n","not_shuffled_W_x = tf.concat([extended_labeled_x, extended_unlabeled_x], axis=0)\n","not_shuffled_W_y = tf.concat([tf.concat([y, y], axis=0), extended_prediction_unlabeled], axis=0)\n","shuffled_index = np.random.permutation(range(1, batch_size*(augmentation_time+3)+1))\n","indexes = tf.where(shuffled_index)\n","W_x, W_y = tf.gather_nd(not_shuffled_W_x, indexes), tf.gather_nd(not_shuffled_W_y, indexes)\n","\n","#Mixupを実施\n","lam = np.random.beta(alpha, alpha)\n","mixed_labeled_x = lam*extended_labeled_x + (1-lam)*W_x[:batch_size*2]\n","mixed_labeled_y = lam*tf.concat([y, y], axis=0) + (1-lam)*W_y[:batch_size*2]\n","mixed_unlabeled_x = lam*extended_unlabeled_x + (1-lam)*W_x[batch_size*2:]\n","mixed_unlabeled_y = lam*extended_prediction_unlabeled + (1-lam)*W_y[batch_size*2:]\n","\n","# ラベル付きデータの損失関数\n","input_layer = tf.reshape(mixed_labeled_x, [-1, 28, 28, 1])\n","conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[4, 4], padding=\"same\", activation=tf.nn.relu)\n","pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n","dropout1 = tf.layers.dropout(inputs=pool1, rate=0.2)\n","conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n","pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n","pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n","dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n","dropout = tf.layers.dropout(inputs=dense, rate=0.2)\n","labeled_logits = tf.layers.dense(inputs=dropout, units=10)\n","labeled_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = labeled_logits, labels = mixed_labeled_y))\n","\n","# ラベル無しデータの損失関数\n","input_layer = tf.reshape(mixed_unlabeled_x, [-1, 28, 28, 1])\n","conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[4, 4], padding=\"same\", activation=tf.nn.relu)\n","pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n","dropout1 = tf.layers.dropout(inputs=pool1, rate=0.2)\n","conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n","pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n","pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n","dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n","dropout = tf.layers.dropout(inputs=dense, rate=0.2)\n","unlabeled_logits = tf.layers.dense(inputs=dropout, units=10)\n","unlabeled_loss = tf.reduce_mean(tf.square(mixed_unlabeled_y - unlabeled_logits))\n","\n","#全体の損失関数\n","loss = labeled_loss + unlabeled_loss\n","\n","# 最適化(勾配降下法)\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n","train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n","\n","#予測値・accuracyの算出\n","prediction_match = tf.equal(tf.argmax(tf.concat([labeled_logits, unlabeled_logits], axis=0), axis=1), tf.argmax(tf.concat([mixed_labeled_y, mixed_unlabeled_y], axis=0), axis=1))\n","accuracy = tf.reduce_mean(tf.cast(prediction_match, tf.float32), name='accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBGOZ4_7CC3u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"6ce9f3a6-ad62-47ad-d752-a315aaa651ba","executionInfo":{"status":"ok","timestamp":1559173080819,"user_tz":-540,"elapsed":1748,"user":{"displayName":"藤井隆史","photoUrl":"","userId":"02292301144144879183"}}},"source":["#mnistのデータをロード\n","from keras.datasets import mnist \n","from keras.utils import np_utils\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train.reshape([-1, 28, 28, 1]).astype(np.float32), x_test.reshape([-1, 28, 28, 1]).astype(np.float32)\n","y_train, y_test = np_utils.to_categorical(y_train, 10).astype(np.float32)[:30000], np_utils.to_categorical(y_test, 10).astype(np.float32)\n","labeled_x_train, unlabeled_x_train = x_train[:30000, :, :, :], x_train[30000:, :, :, :]\n","print('labeled_x_train:     ' + str(labeled_x_train.shape))\n","print('unlabeled_x_train: ' + str(unlabeled_x_train.shape))\n","print('x_test:                     ' + str(x_test.shape))\n","print('y_train:                    ' + str(y_train.shape))\n","print('y_test:                     ' + str(y_test.shape))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["labeled_x_train:     (30000, 28, 28, 1)\n","unlabeled_x_train: (30000, 28, 28, 1)\n","x_test:                     (10000, 28, 28, 1)\n","y_train:                    (30000, 10)\n","y_test:                     (10000, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KkKX3lg6E5wt","colab_type":"code","colab":{}},"source":["batch_size = 500\n","init = tf.global_variables_initializer()\n","\n","with tf.Session() as sess:\n","  init.run()\n","  for num in range(len(labeled_x_train) // batch_size):\n","    labeled_x_batch, unlabeled_x_batch, y_batch = labeled_x_train[num*batch_size:(num+1)*batch_size], unlabeled_x_train[num*batch_size:(num+1)*batch_size], y_train[num*batch_size:(num+1)*batch_size]\n","    train_accuracy =accuracy.eval(feed_dict={labeled_x: labeled_x_batch, unlabeled_x: unlabeled_x_batch, y: y_batch})\n","    sess.run(train_op, feed_dict={labeled_x: labeled_x_batch, unlabeled_x: unlabeled_x_batch, y: y_batch})\n","    print('accuracy: {}'.format(train_accuracy))\n","  print('accuracy: {}'.format(train_accuracy))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ImhOItP7nvlz","colab_type":"text"},"source":["### ラベル付きの訓練データ（30000件）のみで訓練するモデル"]},{"cell_type":"code","metadata":{"id":"2AiUukIudluj","colab_type":"code","colab":{}},"source":["#入力値のplaceholderを作成\n","labeled_x = tf.placeholder(tf.float32, shape=(None, 28, 28, None))\n","y = tf.placeholder(tf.float32, shape=(None,10))\n","\n","input_layer = tf.reshape(labeled_x, [-1, 28, 28, 1])\n","conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[4, 4], padding=\"same\", activation=tf.nn.relu)\n","pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n","dropout1 = tf.layers.dropout(inputs=pool1, rate=0.2)\n","conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[2, 2], padding=\"same\", activation=tf.nn.relu)\n","pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n","pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n","dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n","dropout = tf.layers.dropout(inputs=dense, rate=0.2)\n","logits = tf.layers.dense(inputs=dropout, units=10)\n","\n","\n","# 損失関数\n","loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=logits)\n","\n","# 最適化\n","optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n","train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n","\n","prediction_match = tf.equal(tf.argmax(logits, axis=1), tf.argmax(y, axis=1))\n","accuracy = tf.reduce_mean(tf.cast(prediction_match, tf.float32), name='accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BiNWdq1WgL-b","colab_type":"code","outputId":"7b69e983-e983-4339-bfc6-85a559b460cf","executionInfo":{"status":"ok","timestamp":1558857040290,"user_tz":-540,"elapsed":63330,"user":{"displayName":"藤井隆史","photoUrl":"","userId":"02292301144144879183"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["batch_size = 500\n","init = tf.global_variables_initializer()\n","\n","with tf.Session() as sess:\n","  init.run()\n","  for num in range(len(labeled_x_train) // batch_size):\n","    labeled_x_batch, unlabeled_x_batch, y_batch = labeled_x_train[num*batch_size:(num+1)*batch_size], unlabeled_x_train[num*batch_size:(num+1)*batch_size], y_train[num*batch_size:(num+1)*batch_size]\n","    train_accuracy = accuracy.eval(feed_dict={labeled_x: labeled_x_batch, unlabeled_x: unlabeled_x_batch, y: y_batch})\n","    sess.run(train_op, feed_dict={labeled_x: labeled_x_batch, unlabeled_x: unlabeled_x_batch, y: y_batch})\n","  print('accuracy: {}'.format(train_accuracy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["accuracy: 0.9399999976158142\n"],"name":"stdout"}]}]}